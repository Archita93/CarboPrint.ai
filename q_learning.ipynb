{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/esraaelelimy/carbon_footprint/blob/main/q_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcIpbBYMZJ7P"
   },
   "source": [
    "# Environment Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7hrTWcFCOm47",
    "outputId": "527dc200-252a-4537-a1b3-5131c4f3c0c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /opt/anaconda3/lib/python3.9/site-packages (0.28.1)\r\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (1.0.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (4.5.0)\r\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (0.0.4)\r\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (2.0.0)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (6.0.0)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (1.23.5)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.11.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVaDpPRrBzgx",
    "outputId": "cea481ba-4a1a-4d8f-ee8a-a05ffba3ff6b"
   },
   "outputs": [],
   "source": [
    "# ACTION Reduce by 10%, 20% etc -> increase action space\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from distutils.util import strtobool\n",
    "\n",
    "import gymnasium as gym\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from stable_baselines3.common.buffers import ReplayBuffer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "possible_actions = [\"increase by level 1\",\"increase by level 2\",\"increase by level 3\",\"maintain\",\n",
    "           \"decrease by level 1\",\"decrease by level 2\",\"decrease by level 3\"]\n",
    "\n",
    "action_for_each_state = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RE1J0sBRy7R8"
   },
   "outputs": [],
   "source": [
    "# DOUBTS: Should co2 be considered a state space\n",
    "# state_space1 = (gamma, pue, tdp_watts, config, chips) \n",
    "# state_space2 = (gamma1, pue1, tdp_watts1, config1, chips1) \n",
    "# difference = ce.state1 - ce.state2 \n",
    "# difference is positive -> + reward\n",
    "# difference is negative -> - reward  \n",
    "\n",
    "\n",
    "\n",
    "# goal -> 395-405 -> terminal state reached \n",
    "# budget limit = 100\n",
    "# current e = 500\n",
    "\n",
    "# diff = 400\n",
    "\n",
    "\n",
    "\n",
    "# Environment Implementation \n",
    "class env():\n",
    "    # start from state and then take an action to return next state and the reward in the next state\n",
    "    def __init__(self, curr_state,termination_co2):\n",
    "        # 7 actions can be taken \n",
    "        self.action_space = Discrete(7)  \n",
    "        # set start state\n",
    "        \n",
    "        self.curr_state = curr_state\n",
    "        self.termination_co2 = termination_co2\n",
    "        # self.info_action = (0,0,0,0,0)\n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "    def carbon_emissions(self,curr_state):\n",
    "        product = 1\n",
    "        # state_space1 = (gamma, pue, tdp_watts, config, chips) \n",
    "        for i in range(len(curr_state)):\n",
    "            product *= curr_state[i]\n",
    "        return product\n",
    "    \n",
    "       \n",
    "    def step(self,info_action):\n",
    "        # state_space1 = (gamma, pue, tdp_watts, config, chips) \n",
    "        # info_action = (0,4,5,6,3)\n",
    "        reward = 0\n",
    "        prev_co2 = self.carbon_emissions(self.curr_state)\n",
    "        \n",
    "        # each state component takes an action \n",
    "        state_list = list(self.curr_state)\n",
    "        actions_list = list(info_action)\n",
    "        \n",
    "        for i in range(len(state_list)):\n",
    "            state_list[i] += actions_list[i] \n",
    "            \n",
    "        self.curr_state = tuple(state_list)\n",
    "        \n",
    "        new_state = self.curr_state\n",
    "        \n",
    "        new_co2 = self.carbon_emissions(new_state)\n",
    "        \n",
    "        old_diff = abs(self.termination_co2 - prev_co2)\n",
    "        new_diff = abs(self.termination_co2 - new_co2)\n",
    "        \n",
    "        if new_diff <= 0.1*self.termination_co2:\n",
    "            done = True\n",
    "            reward += 5\n",
    "        else:\n",
    "            # 100 - 500 = 400 -> old diff\n",
    "            # 100 - 200 = 200 -> new diff \n",
    "            # 200 - 400  = - 200 \n",
    "            if new_diff - old_diff >0: \n",
    "                reward -= 1\n",
    "            else:\n",
    "                reward += 1\n",
    "            done = False\n",
    "        # info could be actions_list ?????????\n",
    "        info = {}\n",
    "        return self.curr_state, reward, done, info\n",
    "        \n",
    "    # difference between reset and init\n",
    "    def reset(self, curr_state,termination_co2):\n",
    "        self.action_space = Discrete(7)   \n",
    "        \n",
    "        self.curr_state = curr_state\n",
    "        \n",
    "        self.termination_co2 = termination_co2\n",
    "        \n",
    "        self.info_action = (0,0,0,0,0)\n",
    "        \n",
    "        return curr_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vlTxnNNazPfy",
    "outputId": "dcd6dfd3-55f4-4255-e0bd-44b665027249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10, 21, 32, 43, 54), -1, False, {})\n"
     ]
    }
   ],
   "source": [
    "state = (10,20,30,40,50)\n",
    "env1 = env(state,100)\n",
    "prod = env1.step((0,1,2,3,4))\n",
    "print(prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQS3MCqWZAGK"
   },
   "source": [
    "#   RL Model implementation using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gqJ-urK9Ojcy"
   },
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 7),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ipLZERCAVAST"
   },
   "outputs": [],
   "source": [
    "q_network = QNetwork()\n",
    "optimizer = optim.Adam(q_network.parameters(), lr=1e-3)\n",
    "target_network = QNetwork()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4dd0SZYU2xb",
    "outputId": "9b8b8b7c-a827-444e-d408-00a056f217d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.6260,  2.8154, -2.8098, -6.4876,  3.6412,  3.1954, -1.1593],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 40 * 8 * 221 = 320*221 = 70,720 * 20 * 100 = 141,440,000\n",
    "state = torch.tensor(state,dtype= torch.float32)\n",
    "q_network(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfwjGODyZQK7"
   },
   "source": [
    "# Agent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftKZJb7xZWvv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnvlp2_Taa9a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "qKTaFn7Zccoj",
    "outputId": "46b48c28-84f1-4f85-b4ba-dc85f2157d0f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "_JutvJzCacfy",
    "outputId": "1921f5be-c2b5-4222-a220-0637c0e6cbba"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4FsP_w4bgsP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMZFJ8sXe9mDOxKCQi15Jin",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
