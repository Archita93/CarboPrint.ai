{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/esraaelelimy/carbon_footprint/blob/main/q_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcIpbBYMZJ7P"
   },
   "source": [
    "# Environment Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7hrTWcFCOm47",
    "outputId": "527dc200-252a-4537-a1b3-5131c4f3c0c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /opt/anaconda3/lib/python3.9/site-packages (0.28.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (6.0.0)\r\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (1.0.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (4.5.0)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (1.23.5)\r\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (2.0.0)\r\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (0.0.4)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.11.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVaDpPRrBzgx",
    "outputId": "cea481ba-4a1a-4d8f-ee8a-a05ffba3ff6b"
   },
   "outputs": [],
   "source": [
    "# ACTION Reduce by 10%, 20% etc -> increase action space\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from distutils.util import strtobool\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from stable_baselines3.common.buffers import ReplayBuffer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "possible_actions = [\"increase by level 1\",\"increase by level 2\",\"increase by level 3\",\"maintain\",\n",
    "           \"decrease by level 1\",\"decrease by level 2\",\"decrease by level 3\"]\n",
    "\n",
    "action_for_each_state = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = pd.read_csv(\"Datasets/gamma_modified.csv\")\n",
    "pue = pd.read_csv(\"Datasets/pue_modified.csv\")\n",
    "gpu = pd.read_csv(\"Datasets/gpu_modified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Providers     object\n",
       "PUE          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pue.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions2(dataframe,input_value,column_name,level,info_name):\n",
    "    current_index = dataframe.index[dataframe[column_name] == input_value][0]\n",
    "    info_value = None\n",
    "    new_index = current_index + level\n",
    "    if new_index <=0:\n",
    "        new_index = 0\n",
    "    elif new_index >= dataframe.shape[0]:\n",
    "        new_index = dataframe.shape[0] - 1 \n",
    "    value = dataframe.loc[new_index,column_name]\n",
    "    info_value = dataframe.loc[new_index,info_name]\n",
    "    return [info_value,value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGX Xavier', 30]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions2(gpu,30,\"tdp_watts\",-3,\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Grid Configurations', 20]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_space1 = (gamma, pue, tdp_watts, config, chips) -> 5\n",
    "# info_action = (0,4,5,6,3) -> 7 possible actions\n",
    "# component -> state component's index in the state_space\n",
    "# action -> action space index\n",
    "# state -> state list\n",
    "# value -> is the actual value of the state_space index\n",
    "# 300 -> \n",
    "# state space = [1,2,34,4]\n",
    "# number of chips : 50\n",
    "# config: 20\n",
    "def actions1(component,action,state):\n",
    "    dict_act = {0:1,1:2,2:3,3:0,4:-1,5:-2,6:-3}\n",
    "    input_value = state[component]\n",
    "    if component == 0:\n",
    "        info_value, output_value = actions2(gamma,input_value,\"Gamma\",dict_act[action],\"Regions\")\n",
    "    elif component == 1:\n",
    "        info_value, output_value = actions2(pue,input_value,\"PUE\",dict_act[action],\"Providers\")\n",
    "    elif component == 2: \n",
    "        info_value, output_value = actions2(gpu,input_value,\"tdp_watts\",dict_act[action],\"name\") \n",
    "    elif component == 3:\n",
    "        output_value = input_value + dict_act[action]\n",
    "        if output_value > 20:\n",
    "            output_value = 20\n",
    "        elif output_value <= 0:\n",
    "            output_value = 1  # maybe change it: 1 grid search\n",
    "        info_value = \"Grid Configurations\"\n",
    "    elif component == 4:\n",
    "        # 100 -> 5,000\n",
    "        # actions -> level 1 -> 100 to 101\n",
    "        # 101 -> 5,050\n",
    "        output_value = input_value + dict_act[action]\n",
    "        if output_value > 300:\n",
    "            output_value = 300\n",
    "        elif output_value <= 0:\n",
    "            output_value = 1  # maybe change it : 10 gpus\n",
    "        info_value = \"Number of Chips\"\n",
    "        # 15,000/50 \n",
    "    return [info_value,output_value]\n",
    "            \n",
    "actions1(3,2,[23.916,1.25,125,21,0])     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RE1J0sBRy7R8"
   },
   "outputs": [],
   "source": [
    "# DOUBTS: Should co2 be considered a state space\n",
    "# state_space1 = (gamma, pue, tdp_watts, config, chips) \n",
    "# state_space2 = (gamma1, pue1, tdp_watts1, config1, chips1) \n",
    "# difference = ce.state1 - ce.state2 \n",
    "# difference is positive -> + reward\n",
    "# difference is negative -> - reward  \n",
    "\n",
    "\n",
    "\n",
    "# goal -> 395-405 -> terminal state reached \n",
    "# budget limit = 100\n",
    "# current e = 500\n",
    "\n",
    "# diff = 400\n",
    "\n",
    "\n",
    "\n",
    "# Environment Implementation \n",
    "class env():\n",
    "    # start from state and then take an action to return next state and the reward in the next state\n",
    "    def __init__(self, curr_state,termination_co2):\n",
    "        # 7 actions can be taken \n",
    "        self.action_space = Discrete(7)          \n",
    "        self.curr_state = curr_state\n",
    "        self.termination_co2 = termination_co2\n",
    "        # self.info_action = (0,0,0,0,0)\n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "    def carbon_emissions(self,curr_state):\n",
    "        product = 1\n",
    "        # state_space1 = (gamma, pue, tdp_watts, config, chips) \n",
    "        # 100 -> divided by 5\n",
    "        # 15,000 -> divided by 100\n",
    "        for i in range(len(curr_state)):\n",
    "            product *= curr_state[i]\n",
    "            product = product/ 1000\n",
    "        return product*250\n",
    "    \n",
    "       \n",
    "    def step(self,info_action):\n",
    "        # state_space1 = (gamma, pue, tdp_watts, config, chips) \n",
    "        # info_action = (0,4,5,6,3)\n",
    "        # state_list = [23.916,1.25,125,21,0]\n",
    "        reward = 0\n",
    "        prev_co2 = self.carbon_emissions(self.curr_state)\n",
    "        info_list = []\n",
    "        # each state component takes an action \n",
    "        state_list = list(self.curr_state)\n",
    "        actions_list = list(info_action)\n",
    "        # actions1(component,action,state) -> output_value, info_value\n",
    "        for i in range(len(state_list)):\n",
    "            \n",
    "            result = actions1(i,actions_list[i],state_list)\n",
    "            state_list[i] = result[1]\n",
    "            info_list.append(result[0])\n",
    "        \n",
    "        self.curr_state = state_list\n",
    "        new_state = self.curr_state\n",
    "        \n",
    "        new_co2 = self.carbon_emissions(new_state)\n",
    "        \n",
    "        old_diff = abs(self.termination_co2 - prev_co2)\n",
    "        new_diff = abs(self.termination_co2 - new_co2)\n",
    "        \n",
    "        if new_diff <= 0.1*self.termination_co2:\n",
    "            done = True\n",
    "            reward += 5\n",
    "        else:\n",
    "            # 100 - 500 = 400 -> old diff\n",
    "            # 100 - 200 = 200 -> new diff \n",
    "            # 200 - 400  = - 200 \n",
    "            if new_diff - old_diff >0: \n",
    "                reward -= 1\n",
    "            else:\n",
    "                reward += 1\n",
    "            done = False\n",
    "        # info could be actions_list ?????????\n",
    "        info = {0:\"The recommended country is \"+str(info_list[0]),\n",
    "               1: \"The recommended provider is \"+str(info_list[1]),\n",
    "               2: \"The recommended GPU is \"+str(info_list[2]),\n",
    "               3: \"The recommended number of Grid Configurations  is \"+str(info_list[3])+\" (in batches)\",\n",
    "               4: \"The recommended number of chips is \"+str(info_list[4])+ \" (in batches)\"}\n",
    "        return self.curr_state, reward, done, info\n",
    "        \n",
    "    # difference between reset and init\n",
    "    def reset(self, curr_state,termination_co2):\n",
    "        self.action_space = Discrete(7)   \n",
    "        self.curr_state = curr_state\n",
    "        self.termination_co2 = termination_co2\n",
    "#         self.info_action = (0,0,0,0,0)\n",
    "        return curr_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vlTxnNNazPfy",
    "outputId": "dcd6dfd3-55f4-4255-e0bd-44b665027249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([24.482, 1.2, 85, 18, 1], 1, False, {0: 'The recommended country is Albania', 1: 'The recommended provider is Tencent Cloud', 2: 'The recommended GPU is Intel Xeon E5-2630v4', 3: 'The recommended number of Grid Configurations  is Grid Configurations (in batches)', 4: 'The recommended number of chips is Number of Chips (in batches)'})\n"
     ]
    }
   ],
   "source": [
    "state = [23.916,1.25,125,21,0]\n",
    "env1 = env(state,100)\n",
    "prod = env1.step([0,4,5,6,3])\n",
    "print(prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQS3MCqWZAGK"
   },
   "source": [
    "#   RL Model implementation using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gqJ-urK9Ojcy"
   },
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 35),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ipLZERCAVAST"
   },
   "outputs": [],
   "source": [
    "q_network = QNetwork()\n",
    "optimizer = optim.Adam(q_network.parameters(), lr=1e-3)\n",
    "target_network = QNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4dd0SZYU2xb",
    "outputId": "9b8b8b7c-a827-444e-d408-00a056f217d5"
   },
   "outputs": [],
   "source": [
    "# 40 * 8 * 221 = 320*221 = 70,720 * 20 * 100 = 141,440,000\n",
    "state = torch.tensor(state,dtype= torch.float32)\n",
    "qval = q_network(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfwjGODyZQK7"
   },
   "source": [
    "# Agent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python dqn.py --total-timesteps 500000 \\ 220\n",
    "#     --learning-rate 2.5e-4 \\\n",
    "#     --buffer-size 10000 \\\n",
    "#     --gamma 0.99 \\ 0.9\n",
    "#     --target-network-frequency 500 \\ 30\n",
    "#     --max-grad-norm 0.5 \\\n",
    "#     --batch-size 128 \\\n",
    "#     --start-e 1 \\\n",
    "#     --end-e 0.05 \\\n",
    "#     --exploration-fraction 0.5 \\\n",
    "#     --learning-starts 10000 \\ 15\n",
    "#     --train-frequency 1 \n",
    "#     --tau / 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concise(states):\n",
    "    # tensor of 35 length\n",
    "    tensor_35 = torch.tensor(states)\n",
    "    # Reshape the tensor into a 2D array of size 7x5\n",
    "    tensor_2d = tensor_35.reshape(5, 7)\n",
    "    # Convert the tensor into a NumPy array\n",
    "    array_2d = tensor_2d.numpy()\n",
    "    max_indices = np.argmax(array_2d, axis=1)\n",
    "\n",
    "    return max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concise_target(states):\n",
    "    # tensor of 35 length\n",
    "    tensor_35 = torch.tensor(states)\n",
    "    # Reshape the tensor into a 2D array of size 7x5\n",
    "    tensor_2d = tensor_35.reshape(5, 7)\n",
    "    # Convert the tensor into a NumPy array\n",
    "    array_2d = tensor_2d.numpy()\n",
    "    max_arr = []\n",
    "    for i in range(len(array_2d)):\n",
    "        max_val =np.amax(array_2d[i])\n",
    "        max_arr.append(max_val)\n",
    "    return max_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/5jl4b1d12lvc6g70prn2_rnr0000gn/T/ipykernel_24213/1293452933.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor_35 = torch.tensor(states)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 3, 6, 2, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concise(qval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 rows and 7 columns\n",
    "def rand_action():\n",
    "    rand_indices = []\n",
    "    for i in range(5):\n",
    "        random_num = random.randint(0,6)\n",
    "        rand_indices.append(random_num)\n",
    "    return rand_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 4, 1, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/5jl4b1d12lvc6g70prn2_rnr0000gn/T/ipykernel_24213/1293452933.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor_35 = torch.tensor(states)\n"
     ]
    }
   ],
   "source": [
    "concise(qval)\n",
    "print(rand_action())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_to_val(tensor_array, actions):\n",
    "    # [0,1,2,3,4]\n",
    "    # tensor_array 35\n",
    "    # actions -> index\n",
    "    tensor_35 = torch.tensor(tensor_array)\n",
    "    # Reshape the tensor into a 2D array of size 7x5\n",
    "    tensor_2d = tensor_35.reshape(5, 7)\n",
    "    # Convert the tensor into a NumPy array\n",
    "    array_2d = tensor_2d.numpy()\n",
    "    old_val = []\n",
    "    for i in range(len(actions)):\n",
    "        old_val.append(array_2d[i][actions[i]])\n",
    "    return torch.tensor(old_val,requires_grad = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/5jl4b1d12lvc6g70prn2_rnr0000gn/T/ipykernel_24213/114465958.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor_35 = torch.tensor(tensor_array)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  6.7046,  -8.2481,   8.8695, -11.1665,   8.8082], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_to_val(qval,[0,1,6,5,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_schedule(start_e: float, end_e: float, duration: int, t: int):\n",
    "    slope = (end_e - start_e) / duration\n",
    "    return max(slope * t + start_e, end_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the environment \n",
    "def training(env,terminationco2,current_state):\n",
    "    for global_step in range(220):\n",
    "        epsilon = linear_schedule(1,0.05,0.2*150,global_step)\n",
    "        # prob is more than epsilon -> best action\n",
    "        q_values = None\n",
    "        if epsilon < random.random():\n",
    "            q_values = q_network(torch.Tensor(current_state))\n",
    "            actions = concise(q_values)\n",
    "\n",
    "        else:\n",
    "            actions = rand_action()\n",
    "        \n",
    "        next_state, rewards, termination, infos = env.step(actions)\n",
    "# Plotting, maybe????\n",
    "        # training \n",
    "        # next state\n",
    "        with torch.no_grad():\n",
    "            target_values = target_network(torch.Tensor(next_state))\n",
    "            target_actions = torch.tensor(concise_target(target_values))\n",
    "            \n",
    "            # concise function\n",
    "            # gamma -> 0.9\n",
    "            td_target = rewards + 0.9 * target_actions * (1 - float(termination))\n",
    "            td_target = torch.tensor(td_target, requires_grad=True)\n",
    "        \n",
    "        # old_val : actions [0,1,6,5,3]\n",
    "        old_val = torch.tensor(i_to_val(q_network(torch.Tensor(current_state)),actions),requires_grad=True)\n",
    "#         old_val = q_network(current_state)\n",
    "        \n",
    "        loss = F.mse_loss(td_target, old_val)\n",
    "\n",
    "\n",
    "        # optimize the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # target_network_frequency - 30\n",
    "        # tau - 0.9\n",
    "        \n",
    "        if global_step % 30 == 0:\n",
    "                for target_network_param, q_network_param in zip(target_network.parameters(), q_network.parameters()):\n",
    "                    target_network_param.data.copy_(\n",
    "                        0.9 * q_network_param.data + (0.1) * target_network_param.data\n",
    "                    )\n",
    "                \n",
    "        current_state = next_state\n",
    "    print(current_state)\n",
    "    for value in infos.values():\n",
    "        print(value+\"/n\")\n",
    "    print(\"The new carbon estimation is \"+str(env.carbon_emissions(current_state)))\n",
    "\n",
    "        \n",
    "    # Reset is maybe not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ftKZJb7xZWvv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[311.475, 1.1, 250, 15, 1]\n",
      "The recommended country is Bolivia/n\n",
      "The recommended provider is Google Cloud/n\n",
      "The recommended GPU is Tesla P100/n\n",
      "The recommended number of Grid Configurations  is Grid Configurations (in batches)/n\n",
      "The recommended number of chips is Number of Chips (in batches)/n\n",
      "The new carbon estimation is 3.2120859375e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/5jl4b1d12lvc6g70prn2_rnr0000gn/T/ipykernel_24213/230597155.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor_35 = torch.tensor(states)\n",
      "/var/folders/0g/5jl4b1d12lvc6g70prn2_rnr0000gn/T/ipykernel_24213/330932303.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  td_target = torch.tensor(td_target, requires_grad=True)\n",
      "/var/folders/0g/5jl4b1d12lvc6g70prn2_rnr0000gn/T/ipykernel_24213/114465958.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor_35 = torch.tensor(tensor_array)\n",
      "/var/folders/0g/5jl4b1d12lvc6g70prn2_rnr0000gn/T/ipykernel_24213/330932303.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  old_val = torch.tensor(i_to_val(q_network(torch.Tensor(current_state)),actions),requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "training(env1,500,state)\n",
    "# [23.464, 1.18, 105, 20, 1]\n",
    "# [24.482, 1.1, 105, 3, 7]\n",
    "\n",
    "\n",
    "# 58,143 -> \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnvlp2_Taa9a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "qKTaFn7Zccoj",
    "outputId": "46b48c28-84f1-4f85-b4ba-dc85f2157d0f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "_JutvJzCacfy",
    "outputId": "1921f5be-c2b5-4222-a220-0637c0e6cbba"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4FsP_w4bgsP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMZFJ8sXe9mDOxKCQi15Jin",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
