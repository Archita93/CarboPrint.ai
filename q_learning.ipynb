{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/esraaelelimy/carbon_footprint/blob/main/q_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcIpbBYMZJ7P"
   },
   "source": [
    "# Environment Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7hrTWcFCOm47",
    "outputId": "527dc200-252a-4537-a1b3-5131c4f3c0c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /opt/anaconda3/lib/python3.9/site-packages (0.28.1)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (1.23.5)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (6.0.0)\r\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (0.0.4)\r\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (1.0.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (4.5.0)\r\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (2.0.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.11.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVaDpPRrBzgx",
    "outputId": "cea481ba-4a1a-4d8f-ee8a-a05ffba3ff6b"
   },
   "outputs": [],
   "source": [
    "# ACTION Reduce by 10%, 20% etc -> increase action space\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from distutils.util import strtobool\n",
    "\n",
    "import gymnasium as gym\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from stable_baselines3.common.buffers import ReplayBuffer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "possible_actions = [\"increase by level 1\",\"increase by level 2\",\"increase by level 3\",\"maintain\",\n",
    "           \"decrease by level 1\",\"decrease by level 2\",\"decrease by level 3\"]\n",
    "\n",
    "action_for_each_state = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "RE1J0sBRy7R8"
   },
   "outputs": [],
   "source": [
    "# DOUBTS: Should co2 be considered a state space\n",
    "# state_space1 = (gamma, pue, tdp_watts, config, chips) \n",
    "# state_space2 = (gamma1, pue1, tdp_watts1, config1, chips1) \n",
    "# difference = ce.state1 - ce.state2 \n",
    "# difference is positive -> + reward\n",
    "# difference is negative -> - reward  \n",
    "\n",
    "\n",
    "\n",
    "# goal -> 395-405 -> terminal state reached \n",
    "# budget limit = 100\n",
    "# current e = 500\n",
    "\n",
    "# diff = 400\n",
    "\n",
    "\n",
    "\n",
    "# Environment Implementation \n",
    "class env():\n",
    "    # start from state and then take an action to return next state and the reward in the next state\n",
    "    def __init__(self, curr_state,termination_co2):\n",
    "        # 7 actions can be taken \n",
    "        self.action_space = Discrete(7)          \n",
    "        self.curr_state = curr_state\n",
    "        self.termination_co2 = termination_co2\n",
    "        # self.info_action = (0,0,0,0,0)\n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "    def carbon_emissions(self,curr_state):\n",
    "        product = 1\n",
    "        # state_space1 = (gamma, pue, tdp_watts, config, chips) \n",
    "        for i in range(len(curr_state)):\n",
    "            product *= curr_state[i]\n",
    "        return product\n",
    "    \n",
    "       \n",
    "    def step(self,info_action):\n",
    "        # state_space1 = (gamma, pue, tdp_watts, config, chips) \n",
    "        # info_action = (0,4,5,6,3)\n",
    "        reward = 0\n",
    "        prev_co2 = self.carbon_emissions(self.curr_state)\n",
    "        \n",
    "        # each state component takes an action \n",
    "        state_list = list(self.curr_state)\n",
    "        actions_list = list(info_action)\n",
    "        \n",
    "        for i in range(len(state_list)):\n",
    "            state_list[i] += actions_list[i] \n",
    "            \n",
    "        self.curr_state = state_list\n",
    "        \n",
    "        new_state = self.curr_state\n",
    "        \n",
    "        new_co2 = self.carbon_emissions(new_state)\n",
    "        \n",
    "        old_diff = abs(self.termination_co2 - prev_co2)\n",
    "        new_diff = abs(self.termination_co2 - new_co2)\n",
    "        \n",
    "        if new_diff <= 0.1*self.termination_co2:\n",
    "            done = True\n",
    "            reward += 5\n",
    "        else:\n",
    "            # 100 - 500 = 400 -> old diff\n",
    "            # 100 - 200 = 200 -> new diff \n",
    "            # 200 - 400  = - 200 \n",
    "            if new_diff - old_diff >0: \n",
    "                reward -= 1\n",
    "            else:\n",
    "                reward += 1\n",
    "            done = False\n",
    "        # info could be actions_list ?????????\n",
    "        info = {}\n",
    "        return self.curr_state, reward, done, info\n",
    "        \n",
    "    # difference between reset and init\n",
    "    def reset(self, curr_state,termination_co2):\n",
    "        self.action_space = Discrete(7)   \n",
    "        self.curr_state = curr_state\n",
    "        self.termination_co2 = termination_co2\n",
    "#         self.info_action = (0,0,0,0,0)\n",
    "        return curr_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vlTxnNNazPfy",
    "outputId": "dcd6dfd3-55f4-4255-e0bd-44b665027249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([10, 21, 32, 43, 54], -1, False, {})\n"
     ]
    }
   ],
   "source": [
    "state = [10,20,30,40,50]\n",
    "env1 = env(state,100)\n",
    "prod = env1.step([0,1,2,3,4])\n",
    "print(prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQS3MCqWZAGK"
   },
   "source": [
    "#   RL Model implementation using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "gqJ-urK9Ojcy"
   },
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 35),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "ipLZERCAVAST"
   },
   "outputs": [],
   "source": [
    "q_network = QNetwork()\n",
    "optimizer = optim.Adam(q_network.parameters(), lr=1e-3)\n",
    "target_network = QNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4dd0SZYU2xb",
    "outputId": "9b8b8b7c-a827-444e-d408-00a056f217d5"
   },
   "outputs": [],
   "source": [
    "# 40 * 8 * 221 = 320*221 = 70,720 * 20 * 100 = 141,440,000\n",
    "state = torch.tensor(state,dtype= torch.float32)\n",
    "qval = q_network(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfwjGODyZQK7"
   },
   "source": [
    "# Agent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python dqn.py --total-timesteps 500000 \\ 220\n",
    "#     --learning-rate 2.5e-4 \\\n",
    "#     --buffer-size 10000 \\\n",
    "#     --gamma 0.99 \\ 0.9\n",
    "#     --target-network-frequency 500 \\ 30\n",
    "#     --max-grad-norm 0.5 \\\n",
    "#     --batch-size 128 \\\n",
    "#     --start-e 1 \\\n",
    "#     --end-e 0.05 \\\n",
    "#     --exploration-fraction 0.5 \\\n",
    "#     --learning-starts 10000 \\ 15\n",
    "#     --train-frequency 1 \n",
    "#     --tau / 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concise(states):\n",
    "    # tensor of 35 length\n",
    "    tensor_35 = torch.tensor(states)\n",
    "    # Reshape the tensor into a 2D array of size 7x5\n",
    "    tensor_2d = tensor_35.reshape(5, 7)\n",
    "    # Convert the tensor into a NumPy array\n",
    "    array_2d = tensor_2d.numpy()\n",
    "    max_indices = np.argmax(array_2d, axis=1)\n",
    "\n",
    "    return max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concise_target(states):\n",
    "    # tensor of 35 length\n",
    "    tensor_35 = torch.tensor(states)\n",
    "    # Reshape the tensor into a 2D array of size 7x5\n",
    "    tensor_2d = tensor_35.reshape(5, 7)\n",
    "    # Convert the tensor into a NumPy array\n",
    "    array_2d = tensor_2d.numpy()\n",
    "    max_arr = []\n",
    "    for i in range(len(array_2d)):\n",
    "        max_val =np.amax(array_2d[i])\n",
    "        max_arr.append(max_val)\n",
    "    return max_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/5jl4b1d12lvc6g70prn2_rnr0000gn/T/ipykernel_6158/1293452933.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor_35 = torch.tensor(states)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 5, 3, 2])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concise(qval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 rows and 7 columns\n",
    "def rand_action():\n",
    "    rand_indices = []\n",
    "    for i in range(5):\n",
    "        random_num = random.randint(0,6)\n",
    "        rand_indices.append(random_num)\n",
    "    return rand_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 5, 5, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/5jl4b1d12lvc6g70prn2_rnr0000gn/T/ipykernel_6158/1293452933.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor_35 = torch.tensor(states)\n"
     ]
    }
   ],
   "source": [
    "concise(qval)\n",
    "print(rand_action())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_to_val(tensor_array, actions):\n",
    "    # [0,1,2,3,4]\n",
    "    # tensor_array 35\n",
    "    # actions -> index\n",
    "    tensor_35 = torch.tensor(tensor_array)\n",
    "    # Reshape the tensor into a 2D array of size 7x5\n",
    "    tensor_2d = tensor_35.reshape(5, 7)\n",
    "    # Convert the tensor into a NumPy array\n",
    "    array_2d = tensor_2d.numpy()\n",
    "    old_val = []\n",
    "    for i in range(len(actions)):\n",
    "        old_val.append(array_2d[i][actions[i]])\n",
    "    return torch.tensor(old_val,requires_grad = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/5jl4b1d12lvc6g70prn2_rnr0000gn/T/ipykernel_6158/114465958.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor_35 = torch.tensor(tensor_array)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3.1084, 6.1832, 4.0194, 0.3200, 3.1776], requires_grad=True)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_to_val(qval,[0,1,6,5,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_schedule(start_e: float, end_e: float, duration: int, t: int):\n",
    "    slope = (end_e - start_e) / duration\n",
    "    return max(slope * t + start_e, end_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the environment \n",
    "def training(env,terminationco2,current_state):\n",
    "    for global_step in range(220):\n",
    "        epsilon = linear_schedule(1,0.05,0.2*150,global_step)\n",
    "        # prob is more than epsilon -> best action\n",
    "        q_values = None\n",
    "        if epsilon < random.random():\n",
    "            q_values = q_network(torch.Tensor(current_state))\n",
    "            actions = concise(q_values)\n",
    "\n",
    "        else:\n",
    "            actions = rand_action()\n",
    "        \n",
    "        next_state, rewards, termination, infos = env.step(actions)\n",
    "# Plotting, maybe????\n",
    "        # training \n",
    "        # next state\n",
    "        with torch.no_grad():\n",
    "            target_values = target_network(torch.Tensor(next_state))\n",
    "            target_actions = torch.tensor(concise_target(target_values))\n",
    "            \n",
    "            # concise function\n",
    "            # gamma -> 0.9\n",
    "            print(target_actions.shape)\n",
    "            td_target = rewards + 0.9 * target_actions * (1 - float(termination))\n",
    "            td_target = torch.tensor(td_target, requires_grad=True)\n",
    "        \n",
    "        # old_val : actions [0,1,6,5,3]\n",
    "        old_val = torch.tensor(i_to_val(q_network(current_state),actions),requires_grad=True)\n",
    "        print(\"td_target\",td_target)\n",
    "        print(\"old_val\",old_val)\n",
    "        loss = F.mse_loss(td_target, old_val)\n",
    "\n",
    "\n",
    "        # optimize the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # target_network_frequency - 30\n",
    "        # tau - 0.9\n",
    "        \n",
    "        if global_step % 30 == 0:\n",
    "                for target_network_param, q_network_param in zip(target_network.parameters(), q_network.parameters()):\n",
    "                    target_network_param.data.copy_(\n",
    "                        0.9 * q_network_param.data + (0.1) * target_network_param.data\n",
    "                    )\n",
    "                \n",
    "        current_state = next_state\n",
    "        \n",
    "    # Reset is maybe not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "ftKZJb7xZWvv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "td_target tensor([18.7409, 25.9879, 20.3855, 15.8096, 17.9478], requires_grad=True)\n",
      "old_val tensor([ 3.9806, -2.3744, -1.5180,  4.4136,  4.7259], requires_grad=True)\n",
      "torch.Size([5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/5jl4b1d12lvc6g70prn2_rnr0000gn/T/ipykernel_6158/230597155.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor_35 = torch.tensor(states)\n",
      "/var/folders/0g/5jl4b1d12lvc6g70prn2_rnr0000gn/T/ipykernel_6158/366462886.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  td_target = torch.tensor(td_target, requires_grad=True)\n",
      "/var/folders/0g/5jl4b1d12lvc6g70prn2_rnr0000gn/T/ipykernel_6158/114465958.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor_35 = torch.tensor(tensor_array)\n",
      "/var/folders/0g/5jl4b1d12lvc6g70prn2_rnr0000gn/T/ipykernel_6158/366462886.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  old_val = torch.tensor(i_to_val(q_network(current_state),actions),requires_grad=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[234], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv1\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[233], line 29\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(env, terminationco2, current_state)\u001b[0m\n\u001b[1;32m     26\u001b[0m     td_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(td_target, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# old_val : actions [0,1,6,5,3]\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m old_val \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(i_to_val(\u001b[43mq_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m)\u001b[49m,actions),requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtd_target\u001b[39m\u001b[38;5;124m\"\u001b[39m,td_target)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mold_val\u001b[39m\u001b[38;5;124m\"\u001b[39m,old_val)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[144], line 13\u001b[0m, in \u001b[0;36mQNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "training(env1,100,state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnvlp2_Taa9a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "qKTaFn7Zccoj",
    "outputId": "46b48c28-84f1-4f85-b4ba-dc85f2157d0f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "_JutvJzCacfy",
    "outputId": "1921f5be-c2b5-4222-a220-0637c0e6cbba"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4FsP_w4bgsP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMZFJ8sXe9mDOxKCQi15Jin",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
